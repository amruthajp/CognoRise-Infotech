# -*- coding: utf-8 -*-
"""email.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1tf9cxSwDPCcfTcuDYlHl3wyroOvUqdbP

# **SPAM EMAIL DETECTION**

**IMPORTING LIBRARIES**
"""

import numpy as np
import pandas as pd
import nltk
import re
import matplotlib.pyplot as plt
import seaborn as sns
from nltk.tokenize import TweetTokenizer
from nltk.tokenize import word_tokenize
from nltk.stem import SnowballStemmer
from nltk.corpus import stopwords
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import MinMaxScaler
from sklearn.neighbors import KNeighborsClassifier
from sklearn.ensemble import RandomForestClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import confusion_matrix,accuracy_score,ConfusionMatrixDisplay

"""**DOWNLOADING NLTK RESOURCES**"""

nltk.download('stopwords')
nltk.download('punkt')
nltk.download('wordnet')
nltk.download('omw-1.4')

"""**LOADING DATASET**"""

df=pd.read_csv('/content/spam.csv',encoding="ISO-8859-1")
df

"""**DATA PREPROCESSING**"""

# Printing first five rows
df.head()

# Printing the last 5 rows
df.tail()

# Printing the datatype
df.dtypes

# Printing column names
df.columns

# Number of rows and columns
df.shape

# Checking for missing values
df.isna().sum()

# Describing dataset
df.describe()

#get a concise summary of the DataFrame
df.info()

df['Category'].value_counts()

sns.countplot(x=df['Category'],data=df,color='hotpink')

#Transforming Categorical Data into Numerical Labels
df['Category']=df['Category'].str.replace('spam','0')
df['Category']=df['Category'].str.replace('ham','1')
df

#Converting Data Types for Numerical Analysis
df['Category']=df['Category'].astype(int)
df.dtypes

mail=df.Message
mail

#Tokenization
tk=TweetTokenizer()
mail=mail.apply(lambda x:tk.tokenize(x)).apply(lambda x:" ".join(x))
mail

#Removing Special Characters and Symbols
mail=mail.str.replace('[^A-Za-z-0-9]+',' ')
mail

#Collecting meaningful words by filtering short words
mail=mail.apply(lambda x:' '.join([w for w in word_tokenize (x) if len(w)>=3]))
mail

#Stemming
stemmer=SnowballStemmer('english')
mail=mail.apply(lambda x:[stemmer.stem(i.lower()) for i in tk.tokenize(x)]).apply(lambda x:" ".join(x))
mail

#Removing Stopwords
sw=stopwords.words('english')
mail=mail.apply(lambda x:[i for i in tk.tokenize(x) if i not in sw]).apply(lambda x:" ".join(x))
mail

#Vectorisation
vector=TfidfVectorizer()
train_data=vector.fit_transform(mail)

train_data.shape

y=df['Category'].values
y

"""**SPLITTING DATA FOR TRAINING AND TESTING**"""

x_train,x_test,y_train,y_test=train_test_split(train_data,y,test_size=0.30,random_state=42)
x_train.shape

x_test.shape

y_train

y_test

"""**MODEL CREATION**"""

knn=KNeighborsClassifier(n_neighbors=7)
forest=RandomForestClassifier(n_estimators=100,criterion='entropy')
logistic = LogisticRegression()
models=[knn,forest,logistic]

"""**PERFORMANCE EVALUATION**"""

for i in models:
  print('Model is .....',i)
  i.fit(x_train,y_train)
  print("Prediction is.......")
  y_pred=i.predict(x_test)
  print(y_pred)
  print("Confusion matrix is..........")
  print("matrix is",confusion_matrix(y_test,y_pred))
  print("Accuracy score is .......")
  print("score is",accuracy_score(y_test,y_pred))

"""**CONFUSION MATRIX**"""

cmd=confusion_matrix(y_test,y_pred)
cmd

from sklearn.metrics import ConfusionMatrixDisplay
lab=['ham','spam']
cmd1=ConfusionMatrixDisplay(cmd,display_labels=lab)
cmd1.plot()